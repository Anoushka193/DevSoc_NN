# DevSoc_NN
 This project implements a simple neural network from scratch using NumPy to classify handwritten digits from the MNIST dataset. 
 The network is trained using the backpropagation algorithm and gradient descent to minimize the categorical cross-entropy loss.
 the structure of the network is as follows:
 1. input layer
 2. first hidden layer - ReLU activation function
 3. second hidden layer - tanh activation function
 4. output layer - softmax activation function
